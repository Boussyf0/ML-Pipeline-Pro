{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📊 Customer Churn Data Exploration\n",
    "\n",
    "This notebook explores the Telco Customer Churn dataset from Kaggle to understand the data characteristics and relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Configure display\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "print(\"📊 Data Exploration Setup Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📁 Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the customer churn dataset\n",
    "data_path = \"../data/raw/customer_data.csv\"\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(data_path)\n",
    "    print(f\"✅ Dataset loaded successfully: {df.shape}\")\n",
    "    print(f\"📈 Churn rate: {(df['churn'] == 'Yes').mean():.2%}\")\nexcept FileNotFoundError:\n",
    "    print(\"❌ Dataset not found. Please run the download script first:\")\n",
    "    print(\"   python scripts/download_kaggle_data.py\")\n",
    "    df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔍 Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    print(\"📋 Dataset Info:\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    print(\"\\n📊 Column Info:\")\n",
    "    df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    print(\"🎯 Target Variable Distribution:\")\n",
    "    churn_counts = df['churn'].value_counts()\n",
    "    print(churn_counts)\n",
    "    print(f\"\\nChurn Rate: {churn_counts['Yes'] / len(df):.2%}\")\n",
    "    \n",
    "    # Visualize target distribution\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    # Count plot\n",
    "    sns.countplot(data=df, x='churn', ax=ax1)\n",
    "    ax1.set_title('Churn Distribution (Count)')\n",
    "    ax1.set_xlabel('Churn')\n",
    "    ax1.set_ylabel('Count')\n",
    "    \n",
    "    # Pie chart\n",
    "    colors = ['#FF6B6B', '#4ECDC4']\n",
    "    ax2.pie(churn_counts.values, labels=churn_counts.index, autopct='%1.1f%%', colors=colors)\n",
    "    ax2.set_title('Churn Distribution (Percentage)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📈 Numerical Features Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # Identify numerical columns\n",
    "    numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    if 'customer_id' in numerical_cols:\n",
    "        numerical_cols.remove('customer_id')\n",
    "    \n",
    "    print(f\"📊 Numerical Features ({len(numerical_cols)}): {numerical_cols}\")\n",
    "    \n",
    "    # Descriptive statistics\n",
    "    print(\"\\n📈 Descriptive Statistics:\")\n",
    "    print(df[numerical_cols].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and len(numerical_cols) > 0:\n",
    "    # Distribution plots\n",
    "    n_cols = min(3, len(numerical_cols))\n",
    "    n_rows = (len(numerical_cols) + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 4 * n_rows))\n",
    "    if n_rows == 1:\n",
    "        axes = [axes] if n_cols == 1 else axes\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "    \n",
    "    for i, col in enumerate(numerical_cols):\n",
    "        if i < len(axes):\n",
    "            # Histogram with churn overlay\n",
    "            for churn_val in ['No', 'Yes']:\n",
    "                data = df[df['churn'] == churn_val][col]\n",
    "                axes[i].hist(data, alpha=0.7, label=f'Churn={churn_val}', bins=30)\n",
    "            \n",
    "            axes[i].set_title(f'{col} Distribution by Churn')\n",
    "            axes[i].set_xlabel(col)\n",
    "            axes[i].set_ylabel('Frequency')\n",
    "            axes[i].legend()\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for i in range(len(numerical_cols), len(axes)):\n",
    "        axes[i].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🏷️ Categorical Features Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # Identify categorical columns\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "    if 'customer_id' in categorical_cols:\n",
    "        categorical_cols.remove('customer_id')\n",
    "    if 'churn' in categorical_cols:\n",
    "        categorical_cols.remove('churn')\n",
    "    \n",
    "    print(f\"🏷️ Categorical Features ({len(categorical_cols)}): {categorical_cols}\")\n",
    "    \n",
    "    # Show unique values for each categorical feature\n",
    "    print(\"\\n🔍 Unique Values per Feature:\")\n",
    "    for col in categorical_cols[:5]:  # Show first 5 to avoid clutter\n",
    "        unique_vals = df[col].unique()[:10]  # Show first 10 unique values\n",
    "        print(f\"{col}: {len(df[col].unique())} unique values - {unique_vals}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and len(categorical_cols) > 0:\n",
    "    # Churn rate by categorical features\n",
    "    important_categoricals = categorical_cols[:6]  # Show top 6\n",
    "    \n",
    "    n_cols = 2\n",
    "    n_rows = (len(important_categoricals) + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 4 * n_rows))\n",
    "    if n_rows == 1:\n",
    "        axes = [axes] if n_cols == 1 else axes\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "    \n",
    "    for i, col in enumerate(important_categoricals):\n",
    "        if i < len(axes):\n",
    "            # Calculate churn rate by category\n",
    "            churn_rate = df.groupby(col)['churn'].apply(lambda x: (x == 'Yes').mean()).sort_values(ascending=False)\n",
    "            \n",
    "            # Bar plot\n",
    "            bars = axes[i].bar(range(len(churn_rate)), churn_rate.values, \n",
    "                              color=['#FF6B6B' if rate > 0.3 else '#4ECDC4' for rate in churn_rate.values])\n",
    "            \n",
    "            axes[i].set_title(f'Churn Rate by {col}')\n",
    "            axes[i].set_xlabel(col)\n",
    "            axes[i].set_ylabel('Churn Rate')\n",
    "            axes[i].set_xticks(range(len(churn_rate)))\n",
    "            axes[i].set_xticklabels(churn_rate.index, rotation=45)\n",
    "            \n",
    "            # Add value labels on bars\n",
    "            for bar, rate in zip(bars, churn_rate.values):\n",
    "                axes[i].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                           f'{rate:.2%}', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for i in range(len(important_categoricals), len(axes)):\n",
    "        axes[i].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔗 Feature Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and len(numerical_cols) > 1:\n",
    "    # Correlation matrix for numerical features\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Create correlation matrix\n",
    "    corr_matrix = df[numerical_cols].corr()\n",
    "    \n",
    "    # Heatmap\n",
    "    mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "    sns.heatmap(corr_matrix, mask=mask, annot=True, cmap='RdYlBu_r', center=0,\n",
    "                square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8})\n",
    "    \n",
    "    plt.title('Feature Correlation Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Show strongest correlations\n",
    "    print(\"\\n🔗 Strongest Correlations:\")\n",
    "    corr_pairs = []\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i+1, len(corr_matrix.columns)):\n",
    "            corr_pairs.append((\n",
    "                corr_matrix.columns[i], \n",
    "                corr_matrix.columns[j], \n",
    "                corr_matrix.iloc[i, j]\n",
    "            ))\n",
    "    \n",
    "    corr_pairs.sort(key=lambda x: abs(x[2]), reverse=True)\n",
    "    for feat1, feat2, corr in corr_pairs[:5]:\n",
    "        print(f\"{feat1} ↔ {feat2}: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💡 Key Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    print(\"💡 Key Insights from Data Exploration:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Overall churn rate\n",
    "    churn_rate = (df['churn'] == 'Yes').mean()\n",
    "    print(f\"📈 Overall churn rate: {churn_rate:.1%}\")\n",
    "    \n",
    "    # High-risk segments (if we have categorical data)\n",
    "    if 'contract' in df.columns:\n",
    "        contract_churn = df.groupby('contract')['churn'].apply(lambda x: (x == 'Yes').mean())\n",
    "        highest_risk_contract = contract_churn.idxmax()\n",
    "        print(f\"📋 Highest risk contract type: {highest_risk_contract} ({contract_churn[highest_risk_contract]:.1%} churn rate)\")\n",
    "    \n",
    "    if 'internet_service' in df.columns:\n",
    "        internet_churn = df.groupby('internet_service')['churn'].apply(lambda x: (x == 'Yes').mean())\n",
    "        highest_risk_internet = internet_churn.idxmax()\n",
    "        print(f\"🌐 Highest risk internet service: {highest_risk_internet} ({internet_churn[highest_risk_internet]:.1%} churn rate)\")\n",
    "    \n",
    "    # Tenure analysis\n",
    "    if 'tenure' in df.columns:\n",
    "        avg_tenure_churned = df[df['churn'] == 'Yes']['tenure'].mean()\n",
    "        avg_tenure_retained = df[df['churn'] == 'No']['tenure'].mean()\n",
    "        print(f\"📊 Average tenure - Churned: {avg_tenure_churned:.1f} months, Retained: {avg_tenure_retained:.1f} months\")\n",
    "    \n",
    "    # Monthly charges analysis\n",
    "    if 'monthly_charges' in df.columns:\n",
    "        avg_charges_churned = df[df['churn'] == 'Yes']['monthly_charges'].mean()\n",
    "        avg_charges_retained = df[df['churn'] == 'No']['monthly_charges'].mean()\n",
    "        print(f\"💰 Average monthly charges - Churned: ${avg_charges_churned:.2f}, Retained: ${avg_charges_retained:.2f}\")\n",
    "    \n",
    "    print(\"\\n🎯 Recommendations for Model Training:\")\n",
    "    print(\"• Focus on contract type and tenure as key predictive features\")\n",
    "    print(\"• Consider feature engineering: tenure categories, charges ratios\")\n",
    "    print(\"• Handle class imbalance in churn prediction\")\n",
    "    print(\"• Monitor model performance on high-risk customer segments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀 Next Steps\n",
    "\n",
    "After exploring the data, you can:\n",
    "\n",
    "1. **Train the model**: `python src/models/train.py --data-path data/raw/customer_data.csv`\n",
    "2. **Start the API**: `python scripts/start_api.py`\n",
    "3. **Monitor the model**: Access Grafana at http://localhost:3000\n",
    "4. **Run A/B tests**: `python scripts/ab_test_cli.py create --help`\n",
    "\n",
    "The insights from this exploration will help inform feature engineering and model selection decisions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}